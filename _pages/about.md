---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üôã‚Äç‚ôÇÔ∏è <font color="#4A708B">About Me</font>

Hi! I'm **Qingyuan Liu (ÂàòÂ∫ÜËøú)**, currently a Research Assistant advised by Prof. <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Nanyun (Violet) Peng</a>, Prof. <a href="https://yuyinzhou.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Yuyin Zhou</a> and Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:bold;">Xuan (Sharon) Di</a> at <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1;">UCLA PLUSLAB</a>, <a href="https://ucsc-vlaa.github.io/index.html" style="text-decoration:none; color:#4169E1;">UCSC VLAA Lab</a> and <a href="https://sharondi-columbia.wixsite.com/ditectlab" style="text-decoration:none; color:#4169E1;">Columbia DitecT Lab</a>. I received my M.S. in Computer Engineering at <a href="https://www.columbia.edu/" style="text-decoration:none; color:#4169E1;">Columbia University</a>, advised by Prof. <a href="https://www.cs.columbia.edu/~junfeng/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Junfeng Yang</a> and Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:bold;">Xuan (Sharon) Di</a>. Previously, I earned my Bachelor's degree from the School of Computer Science & Technology at <a href="https://english.hust.edu.cn/" style="text-decoration:none; color:#4169E1;;">Huazhong University of Science and Technology (HUST)</a>. I fortunately received the <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="color:MediumVioletRed; font-weight:bold;">
Columbia Engineering Research Highlight
</a> in 2024.

<br>

<span style="color:red; font-weight:bold;">I am actively seeking Ph.D. opportunities **in related areas!!!**¬†</span><a href="https://tianzhaohaha.github.io/files/CV-Liu.pdf" style="text-decoration:none; color:#4169E1;">CV (last upate: Oct. 2025)</a>

# üî• News

- **2025.09**: &nbsp;üéâüéâ My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on Knowledge Editing was submitted to <a href="https://iclr.cc/Conferences/2026" style="text-decoration:none; color:#4169E1;">ICLR 2026</a>. Huge thanks to <a href="https://jasonforjoy.github.io/" style="text-decoration:none; color:#4169E1;">Jiachen Gu</a> and <a href="https://yyzcowtodd.cn/" style="text-decoration:none; color:#4169E1;">Yunzhi Yao</a>! Check <a href="https://arxiv.org/abs/2510.01172" style="text-decoration:none; color:#4169E1;">SPHERE</a> [<a href="https://github.com/PlusLabNLP/SPHERE" style="text-decoration:none; color:#4169E1;">code</a>]!
- **2025.04**: &nbsp;üéâüéâ My <span style="color:MediumVioletRed; font-weight:bold;">**second-author**</span> research on Controllable Diffusion was accepted by the <a href="https://delta-workshop.github.io/" style="text-decoration:none; color:#4169E1;">ICLR 2025 DeLTa Workshop</a>! Check <a href="https://iclr.cc/virtual/2025/35305" style="text-decoration:none; color:#4169E1;">Balanced Gen.</a>!
- **2025.03**: &nbsp;üéâüéâ My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on AI-Synthetic Detection is now available on arXiv (ICCV score: 442)! Check <a href="https://arxiv.org/abs/2502.14994v1" style="text-decoration:none; color:#4169E1;">LAVID</a>!
- **2024.07**: &nbsp;üéâüéâ Honored to be included in the <a href="https://www.ee.columbia.edu/ms-ee-honors-program" style="text-decoration:none; color:#4169E1;">Columbia 2024 Spring MS Honors Students</a> (TOP 3 in MSCE)!  
- **2024.06**: &nbsp;üéâüéâ My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on Graph Neural Network was published at <a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">ITSC 2024</a>! Check <a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">Causal Adjacency Learning (CAL)</a>!
- **2024.06**: &nbsp;üéâüéâ My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on AI-Synthetic Detection was highlighted as a <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1;">Columbia Engineering Research Highlight</a>! Check <a href="https://arxiv.org/abs/2406.09601" style="text-decoration:none; color:#4169E1;">DIVID</a>!

<br>

# **üìñ** Research Experience

My research aims to bridge the gap between cutting-edge AI capabilities and their responsible real-world applications by building <span style="color:MediumVioletRed; font-weight:bold;">**Trustworthy AI and Efficient AI**</span>. A list of topics I am actively working on:

- **Knowledge Mechanisms and Editing**: to reduce the cost of upgrading LLMs and enable data-efficient alterations to the behavior of LLMs, while ensuring no adverse impact on other inputs. Recent work: <a href="https://arxiv.org/abs/2510.01172" style="text-decoration:none; color:#4169E1;">[SPHERE, ICLR 2026 in submission]</a>
  - Collaborated with <a href="https://jasonforjoy.github.io/" style="text-decoration:none; color:#4169E1;">Jiachen Gu</a> and <a href="https://yyzcowtodd.cn/" style="text-decoration:none; color:#4169E1; font-weight:;">Yunzhi Yao</a>, supervised by Prof. <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1; font-weight:;">Nanyun (Violet) Peng</a> at the PLUSLAB, UCLA. 
- **Foundation Model**: to design large-scale foundation models for medical imaging that integrate multi-modal signals (MRI, CT, and clinical data) for deployment in real-world healthcare scenarios. Recent work: <a href="" style="text-decoration:none; color:#4169E1;">[Guess What's New Here? (:]</a>
  - Collaborated with <a href="https://beckschen.github.io/" style="text-decoration:none; color:#4169E1; font-weight:;">Jieneng Chen</a> and <a href="https://scholar.google.com/citations?user=Bo9xeqMAAAAJ" style="text-decoration:none; color:#4169E1; font-weight:;">Yuhan Wang</a>, supervised by Prof. <a href="https://yuyinzhou.github.io/" style="text-decoration:none; color:#4169E1; font-weight:;">Yuyin Zhou</a> at the VLAA Lab, UCSC. 
- **Controllable Diffusion**: to advance the controllability of diffusion models, extending their capabilities to handle complex, multi-condition, and application-specific generation tasks. Recent work: <a href="" style="text-decoration:none; color:#4169E1;">[Guess What's New Here? (:]</a>, <a href="https://iclr.cc/virtual/2025/35305" style="text-decoration:none; color:#4169E1;">[Balanced Gen., ICLR 2025 DeLTa]</a>, <a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">[CAL, ITSC 2024]</a>
  - Collaborated with <a href="https://zhaobinmo.github.io/" style="text-decoration:none; color:#4169E1; font-weight:;">Zhaobin Mo</a> and <a href="https://bhyan.com/" style="text-decoration:none; color:#4169E1; font-weight:;">Baohua Yan</a>, supervised by Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:;">Xuan (Sharon) Di</a> at the DitecT Lab, Columbia. 
- **AI-Synthetic Detection**: to build reliable techniques for identifying AI-generated and synthetic videos. Recent work: <a href="https://arxiv.org/abs/2502.14994v1" style="text-decoration:none; color:#4169E1;">[LAVID, 2025]</a>, <a href="https://arxiv.org/abs/2406.09601" style="text-decoration:none; color:#4169E1;">[DIVID, CVPR 2024 GenAI]</a>
  - Supervised by Prof. <a href="https://www.cs.columbia.edu/~junfeng/" style="text-decoration:none; color:#4169E1; font-weight:;">Junfeng Yang</a> at Columbia. 

<br>

<span class='anchor' id='-research-experience'></span>



# üìù Publications 

> (*: equal contribution




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2026 in submission</div><img src='images/sphere.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2510.01172" 
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  Energy-Regularized Sequential Model Editing on Hyperspheres
</a>



**Qingyuan Liu\***, Jia-Chen Gu\*, Yunzhi Yao , Hong Wang , Nanyun Peng<br>

- Developed **SPHERE** (Sparse Projection for Hyperspherical Energy Regularized Editing), projecting new knowledge onto sparse subspaces of edited weight to preserve hyperspherical uniformity with rigorous proof linking hyperspherical uniformity and editing stability. Achieved +16.4% average editing capability over baselines while most faithfully preserving general performance on LLaMA3 (8B) and Qwen2.5 (7B). 

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">preprint</div><img src='images/reveal_iccv-mainflow.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2502.14994v1" style="color:#4169E1; text-decoration:none; font-weight:bold;">
  LAVID: An Agentic LVLM Framework for Diffusion-Generated Video Detection
</a>



**Qingyuan Liu**, Yun-Yun Tsai, Ruijian Zha, Pengyuan Shi, Victoria Li Chengzhi Mao and Junfeng Yang

- Designed an agentic framework **LAVID** that leverage Large Vision Language Models (LVLMs) in detecting AI-generated videos. The LVLMs will call external tools to extract additional information from the video to facilitate themselves in the detection.
- Evaluation results show LAVID improves F1 score by 6.2% to 30.2% over the top baseline on the comprehensive dataset across four SOTA LVLMs.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 GenAI</div><img src='images/DIVID.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2406.09601"
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  Turns Out I'm Not Real: Towards Robust Detection of AI-Generated Videos
</a>



**Qingyuan Liu**, Pengyuan Shi, Yun-Yun Tsai, Chengzhi Mao, and Junfeng Yang<br>

- Developed Diffusion Reconstruction Error (DIRE) based method **DIVID** to detect AI-generate videos; achieved a detection accuracy of up to 93.7% for videos from their benchmark dataset of videos generated from Stable Vision Diffusion, Sora, Pika, and Gen-2.
- This work was marked as the <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1; font-weight:bold;">Columbia Engineering Research Highlight</a>.

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2025 DeLTa</div><img src='images/mnist_masked_new.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://openreview.net/pdf?id=RTOgz0maBt" 
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  BALANCED LATENT SPACE OF DIFFUSION MODELS FOR COUNTERFACTUAL GENERATION
</a>



Baohua Yan, **Qingyuan Liu**, Zhaobin Mo, Kangrui Ruan and Xuan Di<br>

- we propose a framework that balances the latent space by incorporating signals that facilitate the transition to new counterfactuals while preserving factual information. We first identify the cause of this imbalance as the uncontrolled signal from the counterfactuals. Based on this understanding, we introduce a balancing method within the diffusion process. 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ITSC 2024</div><img src='images/CAL.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2411.16142"
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  Causal Adjacency Learning for Spatiotemporal Prediction Over Graphs
</a>



Zhaobin Mo*, **Qingyuan Liu\***, Baohua Yan, Longxiang Zhang, and Xuan Di<br>

- Designed the **C**ausal **A**djacency **L**earning (**CAL**) framework, enhancing model prediction performance on the ODD dataset; applied with the heuristic method which contained the correlation calculation and Condition Independence Test.
- Achieved 14.23%, 15.49%, and 50.27% RMSE improvement in SafeGraph dataset, compared with the results based on distance, correlation, and attention matrix separately.

</div>
</div>



<a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12303/2642855/Accurate-face-swap-using-cycleGAN/10.1117/12.2642855.short" style="text-decoration:none; color:#4169E1;">Accurate face swap using cycleGAN</a>, **Qingyuan Liu**, Yuxuan Zhou, and Shuai Bao, Proc. SPIE 12303, International Conference on Cloud Computing, Internet of Things, and Computer Applications (**CICA**), 2022



<span class='anchor' id='-interesting-hardware-projects'></span>

# üìö Interesting Hardware Projects 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/BUBBLE.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
**Bubble Bobble Game**<br>
<a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/reports/Bubble-Bobble-report.pdf" style="text-decoration:none; color:#4169E1;">Report</a> \| <a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/reports/Bubble-Bobble-presentation.pdf" style="text-decoration:none; color:#4169E1;">Presentation</a>

Course Project of CSEE4840 Embedded Systems, CU (<a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/index.html" style="text-decoration:none; color:#4169E1;">Rated 1st</a>)

- Designed and implemented bubble bobble game on an embedded system utilizing both the ARM CPU and the FPGA on the DE1-SoC, with a focus on efficient video and audio processing. The system is based on line buffer, integrating various hardware inputs of VGA, Game Controller, Audio Jack, and Keyboard.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/C4.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Research on 5G Network Slicing System and Strategy for End Users**<br>

<a href="https://tianzhaohaha.github.io/files/‰ΩúÂìÅËÆæËÆ°ÊñáÊ°£.pdf" style="text-decoration:none; color:#4169E1;">Report</a> \| <a href="https://tianzhaohaha.github.io/files/Èù¢ÂêëÁªàÁ´ØÁî®Êà∑ÁöÑ5GÂàáÁâáÁ≥ªÁªüÂèäÁ≠ñÁï•Á†îÁ©∂_ÊºîÁ§∫PPT.pptx" style="text-decoration:none; color:#4169E1;">Presentation</a>

National Second Prize (Top 3% out of 1006 teams worldwide) in C4

- Applied Reinforcement Learning method to optimize network slicing strategy; tested strategy with 12 cellphones, increasing network throughput by 69.4% and document transfer efficiency by 82.2%.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/MIPS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
**Microprocessor without Interlocked Pipeline Stages (MIPS) CPU Design**<br>

<a href="https://tianzhaohaha.github.io/files/CSXJ1901_U201911111_ÂàòÂ∫ÜËøú_Á°¨‰ª∂ÁªºÂêàËÆ≠ÁªÉËØæÁ®ãËÆæËÆ°Êä•Âëä.pdf" style="text-decoration:none; color:#4169E1;">Report</a>

- Designed a CPU from the scratch with MIPS framework on the Logisim platform; Practical structures have been integrated here such as Pipeline Stalling and Brach History table.

</div>
</div>

<span class='anchor' id='-honors-and-awards'></span>

# üèÜÔ∏è Honors and Awards
- *2024.10* Advanced Master Research Student. 
- *2024.08* <a href="https://www.ee.columbia.edu/ms-ee-honors-program" style="text-decoration:none; color:#4169E1;">2024 Spring MS Honors Students</a> (Rank Top 3 in MSCE).  
- *2024.06* <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1;">Columbia Engineering Research Highlight</a>.  
- *2023.1* National Second Prize in the China Collegiate Computing Contest-Network Technology Challenge (C4) (TOP 3%). 

<span class='anchor' id='-educations'></span>

# üìñ Educations
- *2023.09 - 2025.06*, <a href="https://www.columbia.edu/" style="text-decoration:none; color:#4169E1;">Columbia University</a>, New York, USA  
- *2019.09 - 2023.06*, <a href="https://english.hust.edu.cn/" style="text-decoration:none; color:#4169E1;">Huazhong University of Science and Technology</a>, Wuhan, China  
- *2016.09 - 2019.06*, <a href="https://zh.wikipedia.org/wiki/%E5%A4%A9%E6%B4%A5%E5%B8%82%E6%96%B0%E5%8D%8E%E4%B8%AD%E5%AD%A6" style="text-decoration:none; color:#4169E1;">Tianjin Xinhua High School</a>, Tianjin, China  

<span class='anchor' id='-visitor-map'></span>

# üåèÔ∏è <font color="#4A708B">Visitor Map</font>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=712&t=m&d=NdMaGhwb-9LTDJ4hxiff-LcRvQDUeyHJTqUN9kPjXi8&cmo=ff0707&cmn=ffa451'></script>

