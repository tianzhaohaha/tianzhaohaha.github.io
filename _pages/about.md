---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# 🙋‍♂️ <font color="#4A708B">About Me</font>

Hi! I'm **Qingyuan Liu (刘庆远)**, currently a Research Assistant at <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1;">UCLA PLUSLAB</a>, <a href="https://ucsc-vlaa.github.io/index.html" style="text-decoration:none; color:#4169E1;">USCS VLAA Lab</a> and <a href="https://sharondi-columbia.wixsite.com/ditectlab" style="text-decoration:none; color:#4169E1;">Columbia DitecT Lab</a> advised by Prof. <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Nanyun (Violet) Peng</a>, Prof. <a href="https://yuyinzhou.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Yuyin Zhou</a> and Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:bold;">Xuan (Sharon) Di</a>. I received my M.S. in Computer Engineering at <a href="https://www.columbia.edu/" style="text-decoration:none; color:#4169E1;">Columbia University</a>, advised by Prof. <a href="https://www.cs.columbia.edu/~junfeng/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Junfeng Yang</a> and Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:bold;">Xuan (Sharon) Di</a>. Previously, I earned my Bachelor's degree from the School of Computer Science & Technology at <a href="https://english.hust.edu.cn/" style="text-decoration:none; color:#4169E1;;">Huazhong University of Science and Technology (HUST)</a>. I fortunately received the <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="color:MediumVioletRed; font-weight:bold;">
Columbia Engineering Research Highlight
</a> in 2024.

<br><br>



<span style="color:red; font-weight:bold;">I am actively seeking Ph.D. opportunities **in related areas!!!**</span>



# 🔥 News

- **2025.09**: &nbsp;🎉🎉 My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research <a href="https://arxiv.org/abs/2510.01172" style="text-decoration:none; color:#4169E1;">SPHERE</a> with <a href="https://github.com/PlusLabNLP/SPHERE" style="text-decoration:none; color:#4169E1;">code</a> on model editing was submitted to <a href="https://iclr.cc/Conferences/2026" style="text-decoration:none; color:#4169E1;">ICLR 2026</a>. Huge thanks to <a href="https://jasonforjoy.github.io/" style="text-decoration:none; color:#4169E1;">Jiachen Gu</a> and <a href="https://yyzcowtodd.cn/" style="text-decoration:none; color:#4169E1;">Yunzhi Yao</a>!  
- **2025.04**: &nbsp;🎉🎉 My <span style="color:MediumVioletRed; font-weight:bold;">**second-author**</span> research on Controllable Diffusion Generation was accepted by the <a href="https://delta-workshop.github.io/" style="text-decoration:none; color:#4169E1;">ICLR 2025 DeLTa Workshop</a>!  

- **2025.03**: &nbsp;🎉🎉 My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on AI-Generated Video Detection <a href="https://arxiv.org/abs/2502.14994v1" style="text-decoration:none; color:#4169E1;">LAVID</a> is now available on arXiv!  

- **2024.07**: &nbsp;🎉🎉 Honored to be included in the <a href="https://www.ee.columbia.edu/ms-ee-honors-program" style="text-decoration:none; color:#4169E1;">Columbia 2024 Spring MS Honors Students</a> (TOP 3 in MSCE)!  

- **2024.06**: &nbsp;🎉🎉 My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on (<a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">Causal Adjacency Learning (CAL)</a>) in graph machine learning was published at <a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">ITSC 2024</a>!  

- **2024.06**: &nbsp;🎉🎉 My <span style="color:MediumVioletRed; font-weight:bold;">**first-author**</span> research on AI-Generated Video Detection <a href="https://arxiv.org/abs/2406.09601" style="text-decoration:none; color:#4169E1;">DIVID</a> was highlighted as a <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1;">Columbia Engineering Research Highlight</a>!  

<br>



# **📖** Research Experience

My research aims to bridge the gap between cutting-edge AI capabilities and their responsible real-world applications by building <span style="color:MediumVioletRed; font-weight:bold;">**Trustworthy AI and Efficient AI**</span>. A list of topics I am actively working on:

- **Model Editing**: to reduce the cost of upgrading LLMs and enable data-efficient alterations to the behavior of LLMs, while ensuring no adverse impact on other inputs. Recent work: <a href="https://arxiv.org/abs/2510.01172" style="text-decoration:none; color:#4169E1;">[SPHERE, ICLR 2026 submission]</a>
  - Collaborated with <a href="https://jasonforjoy.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Jiachen Gu</a> and <a href="https://yyzcowtodd.cn/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Yunzhi Yao</a>, supervised by Prof. <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Nanyun (Violet) Peng</a> at the <a href="https://violetpeng.github.io/" style="text-decoration:none; color:#4169E1;">UCLA PLUSLAB</a>. 
- **Foundation Model**: to design large-scale foundation models for medical imaging that integrate multi-modal signals (MRI, CT, and clinical data) for deployment in real-world healthcare scenarios. Recent work: <a href="" style="text-decoration:none; color:#4169E1;">[Guess What's New Here? (:]</a>
  - Collaborated with <a href="https://beckschen.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Jieneng Chen</a> and <a href="https://scholar.google.com/citations?user=Bo9xeqMAAAAJ" style="text-decoration:none; color:#4169E1; font-weight:bold;">Yuhan Wang</a>, supervised by Prof. <a href="https://yuyinzhou.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Yuyin Zhou</a> at the <a href="https://ucsc-vlaa.github.io/index.html" style="text-decoration:none; color:#4169E1;">VLAA Lab</a>, UCSC. 
- **Controllable Diffusion**: to advance the controllability of diffusion models, extending their capabilities to handle complex, multi-condition, and application-specific generation tasks. Recent work: <a href="https://delta-workshop.github.io/" style="text-decoration:none; color:#4169E1;">[Balanced Gen., ICLR 2025 DeLTa]</a>, <a href="https://ieee-itsc.org/2024/" style="text-decoration:none; color:#4169E1;">[CAL, ITSC 2024]</a>
  - Collaborated with <a href="https://zhaobinmo.github.io/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Zhaobin Mo</a> and <a href="https://bhyan.com/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Baohua Yan</a>, supervised by Prof. <a href="https://www.engineering.columbia.edu/faculty/sharon-di" style="text-decoration:none; color:#4169E1; font-weight:bold;">Xuan (Sharon) Di</a> at the <a href="https://sharondi-columbia.wixsite.com/ditectlab" style="text-decoration:none; color:#4169E1;">DitecT Lab</a>, Columbia. 
- **AI-Synthetic Detection**: to build reliable techniques for identifying AI-generated and synthetic videos. Recent work: <a href="https://arxiv.org/abs/2502.14994v1" style="text-decoration:none; color:#4169E1;">[LAVID, 2025]</a>, <a href="https://arxiv.org/abs/2406.09601" style="text-decoration:none; color:#4169E1;">[DIVID, CVPR 2024 GenAI]</a>
  - Supervised by Prof. <a href="https://www.cs.columbia.edu/~junfeng/" style="text-decoration:none; color:#4169E1; font-weight:bold;">Junfeng Yang</a> at Columbia. 

<br><br>



# 📝 Publications 

> (*: equal contribution)

## 🎬AI-Generated Video Detection

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 GenAI</div><img src='images/reveal_iccv-mainflow.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2502.14994v1" style="color:#4169E1; text-decoration:none; font-weight:bold;">
  LAVID: An Agentic LVLM Framework for Diffusion-Generated Video Detection
</a>
**Qingyuan Liu**, Yun-Yun Tsai, Ruijian Zha, Pengyuan Shi, Victoria Li and Junfeng Yang


- Designed an agentic framework **LAVID** that leverage Large Vision Language Models (LVLMs) in detecting AI-generated videos. The LVLMs will call external tools to extract additional information from the video to facilitate themselves in the detection.
- Evaluation results show LAVID improves F1 score by 6.2% to 30.2% over the top baseline on the comprehensive dataset across four SOTA LVLMs.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024 GenAI</div><img src='images/DIVID.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2406.09601"
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  Turns Out I'm Not Real: Towards Robust Detection of AI-Generated Videos
</a>



**Qingyuan Liu**, Pengyuan Shi, Yun-Yun Tsai, Chengzhi Mao, and Junfeng Yang<br>

- Developed Diffusion Reconstruction Error (DIRE) based method **DIVID** to detect AI-generate videos; achieved a detection accuracy of up to 93.7% for videos from their benchmark dataset of videos generated from Stable Vision Diffusion, Sora, Pika, and Gen-2.
- This work was marked as the <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1; font-weight:bold;">Columbia Engineering Research Highlight</a>.

</div>
</div>

## 🚗Controllable Diffusion Generation

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2025 DeLTa</div><img src='images/mnist_masked_new.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://openreview.net/pdf?id=RTOgz0maBt" 
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  BALANCED LATENT SPACE OF DIFFUSION MODELS FOR COUNTERFACTUAL GENERATION
</a>






Baohua Yan, **Qingyuan Liu**, Zhaobin Mo, Kangrui Ruan and Xuan Di<br>

- we propose a framework that balances the latent space by incorporating signals that facilitate the transition to new counterfactuals while preserving factual information. We first identify the cause of this imbalance as the uncontrolled signal from the counterfactuals. Based on this understanding, we introduce a balancing method within the diffusion process. 

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ITSC 2024</div><img src='images/CAL.png' alt="sym" style="width: 100%"></div></div>
<div class='paper-box-text' markdown="1">
<a href="https://arxiv.org/abs/2411.16142"
   style="color:#4169E1 !important; text-decoration:none !important; font-weight:bold;">
  Causal Adjacency Learning for Spatiotemporal Prediction Over Graphs
</a>



Zhaobin Mo*, **Qingyuan Liu\***, Baohua Yan, Longxiang Zhang, and Xuan Di<br>

- Designed the **C**ausal **A**djacency **L**earning (**CAL**) framework, enhancing model prediction performance on the ODD dataset; applied with the heuristic method which contained the correlation calculation and Condition Independence Test.
- Achieved 14.23%, 15.49%, and 50.27% RMSE improvement in SafeGraph dataset, compared with the results based on distance, correlation, and attention matrix separately.

</div>
</div>

## 🔍Other

- <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12303/2642855/Accurate-face-swap-using-cycleGAN/10.1117/12.2642855.short" style="text-decoration:none; color:#4169E1;">Accurate face swap using cycleGAN</a>, **Qingyuan Liu**, Yuxuan Zhou, and Shuai Bao, Proc. SPIE 12303, International Conference on Cloud Computing, Internet of Things, and Computer Applications (**CICA**), 2022

<span class='anchor' id='--selected-projects'></span>

# 📚 Selected Projects 

<div class='paper-box'><div class='paper-box-image'><div><img src='images/BUBBLE.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
**Bubble Bobble Game**<br>

<a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/reports/Bubble-Bobble-report.pdf" style="text-decoration:none; color:#4169E1;">Report</a> \| <a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/reports/Bubble-Bobble-presentation.pdf" style="text-decoration:none; color:#4169E1;">Presentation</a>

Course Project of CSEE4840 Embedded Systems, CU (<a href="https://www.cs.columbia.edu/~sedwards/classes/2024/4840-spring/index.html" style="text-decoration:none; color:#4169E1;">Rated 1st</a>)

- Designed and implemented bubble bobble game on an embedded system utilizing both the ARM CPU and the FPGA on the DE1-SoC, with a focus on efficient video and audio processing. The system is based on line buffer, integrating various hardware inputs of VGA, Game Controller, Audio Jack, and Keyboard.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/C4.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

**Research on 5G Network Slicing System and Strategy for End Users**<br>

<a href="https://tianzhaohaha.github.io/files/作品设计文档.pdf" style="text-decoration:none; color:#4169E1;">Report</a> \| <a href="https://tianzhaohaha.github.io/files/面向终端用户的5G切片系统及策略研究_演示PPT.pptx" style="text-decoration:none; color:#4169E1;">Presentation</a>

National Second Prize (Top 3% out of 1006 teams worldwide) in C4

- Applied Reinforcement Learning method to optimize network slicing strategy; tested strategy with 12 cellphones, increasing network throughput by 69.4% and document transfer efficiency by 82.2%.

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><img src='images/MIPS.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">
**Microprocessor without Interlocked Pipeline Stages (MIPS) CPU Design**<br>

<a href="https://tianzhaohaha.github.io/files/CSXJ1901_U201911111_刘庆远_硬件综合训练课程设计报告.pdf" style="text-decoration:none; color:#4169E1;">Report</a>

- Designed a CPU from the scratch with MIPS framework on the Logisim platform; Practical structures have been integrated here such as Pipeline Stalling and Brach History table.

</div>
</div>

<span class='anchor' id='-honors-and-awards'></span>

# 🏆️ Honors and Awards
- *2024.10* Advanced Master Research Student. 
- *2024.08* <a href="https://www.ee.columbia.edu/ms-ee-honors-program" style="text-decoration:none; color:#4169E1;">2024 Spring MS Honors Students</a>.  
- *2024.06* <a href="https://www.engineering.columbia.edu/about/news/turns-out-im-not-real-detecting-ai-generated-videos" style="text-decoration:none; color:#4169E1;">Columbia Engineering Research Highlight</a>.  
- *2022.10* National Second Prize in the China Collegiate Computing Contest-Network Technology Challenge (C4). 

<span class='anchor' id='-educations'></span>

# 📖 Educations
- *2023.09 - 2025.06*, <a href="https://www.columbia.edu/" style="text-decoration:none; color:#4169E1;">Columbia University</a>, New York, USA  
- *2019.09 - 2023.06*, <a href="https://english.hust.edu.cn/" style="text-decoration:none; color:#4169E1;">Huazhong University of Science and Technology</a>, Wuhan, China  
- *2016.09 - 2019.06*, <a href="https://zh.wikipedia.org/wiki/%E5%A4%A9%E6%B4%A5%E5%B8%82%E6%96%B0%E5%8D%8E%E4%B8%AD%E5%AD%A6" style="text-decoration:none; color:#4169E1;">Tianjin Xinhua High School</a>, Tianjin, China  

<span class='anchor' id='-visitor-map'></span>

# 🌏️ <font color="#4A708B">Visitor Map</font>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=712&t=m&d=NdMaGhwb-9LTDJ4hxiff-LcRvQDUeyHJTqUN9kPjXi8&cmo=ff0707&cmn=ffa451'></script>

